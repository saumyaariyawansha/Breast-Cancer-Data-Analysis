{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and assign X and Y variables\n",
    "dataset = load_breast_cancer()\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.Series(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "dt = DecisionTreeClassifier()\n",
    "params = {'criterion': ['gini', 'entropy'],                   # splitting rule\n",
    "          'max_depth': [None, 3, 5, 10, 20],                  # how deep the tree can go\n",
    "          'min_samples_split': [2, 5, 10, 20],                # min samples needed to split a node\n",
    "          'min_samples_leaf': [1, 2, 4, 10],                  # min samples required at a leaf\n",
    "          'max_features': [None, 'sqrt', 'log2'],             # features considered when splitting\n",
    "          'class_weight': [None, 'balanced']}                 # balance class distribution\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=params, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "dt_pred = grid_search.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n",
    "dt_cm = confusion_matrix(y_test, dt_pred)\n",
    "dt_cr = classification_report(y_test, dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression())                \n",
    "])\n",
    "\n",
    "params = {\n",
    "    'logreg__penalty': ['l2'],                      # type of regularization\n",
    "    'logreg__C': [0.01, 0.1, 1],                    # inverse of regularization strength (smaller = stronger regularization)\n",
    "    'logreg__solver': ['lbfgs', 'liblinear'],       # optimization algorithm (depends on penalty type)\n",
    "    'logreg__max_iter': [500, 1000]}                # max number of iterations for solver to converge\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=params, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "lr_pred = grid_search.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "lr_cm = confusion_matrix(y_test, lr_pred)\n",
    "lr_cr = classification_report(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],                    # number of neighbors to consider\n",
    "    'weights': ['uniform', 'distance'],                     # all neighbors equal vs closer neighbors weighted more\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],      # distance function\n",
    "    'p': [1, 2]}                                            # power parameter (1=Manhattan, 2=Euclidean, only for Minkowski)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=params, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "knn_pred = grid_search.predict(X_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "knn_cm = confusion_matrix(y_test, knn_pred)\n",
    "knn_cr = classification_report(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "\n",
      "Accuracy: 0.9580\n",
      "\n",
      "Confusion matrix:\n",
      " [[47  3]\n",
      " [ 3 90]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        50\n",
      "           1       0.97      0.97      0.97        93\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.95      0.95      0.95       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Model evaluation for Decision Tree\n",
    "print('Decision Tree:\\n')\n",
    "print(f'Accuracy: {dt_acc:.4f}\\n')\n",
    "print('Confusion matrix:\\n', dt_cm)\n",
    "print('\\nClassification report:\\n', dt_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "\n",
      "Accuracy: 0.9860\n",
      "\n",
      "Confusion matrix:\n",
      " [[49  1]\n",
      " [ 1 92]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        50\n",
      "           1       0.99      0.99      0.99        93\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Model evaluation for Logistic Regression\n",
    "print('\\nLogistic Regression:\\n')\n",
    "print(f'Accuracy: {lr_acc:.4f}\\n')\n",
    "print('Confusion matrix:\\n', lr_cm)\n",
    "print('\\nClassification report:\\n', lr_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN:\n",
      "\n",
      "Accuracy: 0.9441\n",
      "\n",
      "Confusion matrix:\n",
      " [[46  4]\n",
      " [ 4 89]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        50\n",
      "           1       0.96      0.96      0.96        93\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.94      0.94       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Model evaluation for KNN\n",
    "print('\\nKNN:\\n')\n",
    "print(f'Accuracy: {knn_acc:.4f}\\n')\n",
    "print('Confusion matrix:\\n', knn_cm)\n",
    "print('\\nClassification report:\\n', knn_cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VI_Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
